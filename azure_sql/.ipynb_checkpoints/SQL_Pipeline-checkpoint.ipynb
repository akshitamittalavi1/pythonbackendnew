{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33ef7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyodbc\n",
    "from azure.storage.blob import BlobServiceClient, BlobClient, ContainerClient\n",
    "from config import BLOB_CONN_STRING,BLOB_CONTAINER1, OPENAI_API_KEY, OPENAI_API_TYPE, OPENAI_API_BASE, OPENAI_API_VERSION, SERVER, DATABASE, USERNAME, PASSWORD, DRIVER\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd959f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb517f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Table_QA:\n",
    "  \n",
    "    def __init__(self, ):\n",
    "        \"\"\"\n",
    "        Initializes parameters and adds default values.\n",
    "        \"\"\"\n",
    "        self.instructions = f\"Given an input question, respond with proper SQLite Query as per the schema provided and consider nth Order as nth row. For example, first order will return values from all the columns of first row and so on. \"\n",
    "        self.data_schema = \"We have three tables, The first table is aggregated_transaction_type_data table which has columns: States(str), Transaction_Year(int), Quarters(int),  Transaction_Type(str), Transaction_Count(int), Transaction_Amount(float)., in which Transaction type has unique values as recharge & bill payments, peer-to-peer payments, merchant payments, financial Services, Others.\\\n",
    "        The second table is aggregated_transaction_device_data table which has columns: States(str), Transaction_Year(int), Quarters(int), Device_Brand(str), Device_Transaction_count(int), Device_Transaction_Percentage(float) \\\n",
    "        and The third table is top_transaction_data table which has columns: States(str), Transaction_Year(int), Quarters(int), District(str), RegisteredUsers(int), Transaction_Type(str), Transaction_Count(int), Transaction_Amount(float)\"\n",
    "        self.prompt2 = \"Generate a natural language answer for the following SQL query and tabular answer and if the dictionary is given and the value is only needed then give only that :\\n\\n\"\n",
    "        connection_string = f\"DRIVER={driver};SERVER={server};DATABASE={database};UID={username};PWD={password}\"\n",
    "        \n",
    "        \n",
    "        \n",
    "    def get_data(self, filename):\n",
    "        \"\"\"\n",
    "        Loads the tabular data for question answering in natural language.\n",
    "        \"\"\"     \n",
    "        blob_service_client = BlobServiceClient.from_connection_string(BLOB_CONN_STRING)\n",
    "        container_client = blob_service_client.get_container_client(BLOB_CONTAINER1)\n",
    "        blob_client = container_client.get_blob_client(filename)\n",
    "\n",
    "        with open(filename, \"wb\") as data:\n",
    "            data.write(blob_client.download_blob().readall())\n",
    "            \n",
    "        return True\n",
    "    \n",
    "    def table_insertion(self, excel_data):\n",
    "        # Connect to the Azure SQL database using the connection string\n",
    "        conn = pyodbc.connect(connectionString)\n",
    "        cursor = conn.cursor()\n",
    "\n",
    "        # Split the file path by the dot (.) to get the filename and extension\n",
    "        sql_table_name, extension = file_path.split(\".\")\n",
    "\n",
    "        if extension == 'csv':\n",
    "            excel_data = pd.read_csv(file_path)\n",
    "        else:\n",
    "            excel_data = pd.read_excel(file_path)\n",
    "\n",
    "        # Convert column names to lowercase\n",
    "        excel_data.columns = excel_data.columns.str.lower()\n",
    "\n",
    "        # Get column names as a tuple\n",
    "        column_names_tuple = tuple(excel_data.columns.tolist())\n",
    "\n",
    "        # Get the column names from the DataFrame\n",
    "        column_names = \", \".join(excel_data.columns)\n",
    "\n",
    "        columns_type = {}\n",
    "        for column_name, dtype in excel_data.dtypes.items():\n",
    "            if dtype == 'int64':\n",
    "                columns_type[column_name] = 'INTEGER'\n",
    "            elif dtype == 'float64':\n",
    "                columns_type[column_name] = 'FLOAT'\n",
    "            elif dtype == 'bool':\n",
    "                columns_type[column_name] = 'BOOLEAN'\n",
    "            elif dtype == 'datetime64[ns]':\n",
    "                columns_type[column_name] = 'DATETIME'\n",
    "            else:\n",
    "                columns_type[column_name] = 'VARCHAR(MAX)'\n",
    "\n",
    "        col_name_type = ''\n",
    "        for column_name, dtype in columns_type.items():\n",
    "            if col_name_type:\n",
    "                col_name_type += f', {column_name} {dtype}'\n",
    "            else:\n",
    "                col_name_type += f'{column_name} {dtype}'\n",
    "\n",
    "        print(f'CREATE TABLE {sql_table_name} ({col_name_type})')\n",
    "        cursor.execute(f'CREATE TABLE {sql_table_name} ({col_name_type})')\n",
    "        # Iterate through rows and insert data\n",
    "        for _, row in excel_data.iterrows():\n",
    "            # Create a parameterized SQL INSERT statement\n",
    "            placeholders = \", \".join([\"?\" for _ in excel_data.columns])\n",
    "            sql_insert = f\"INSERT INTO {sql_table_name} ({column_names}) VALUES ({placeholders})\"\n",
    "\n",
    "            # Extract the values from the row as a tuple\n",
    "            values = tuple(row)\n",
    "            # Execute the SQL INSERT statement with the values\n",
    "            cursor.execute(sql_insert, values)\n",
    "            conn.commit()\n",
    "\n",
    "        cursor.close()\n",
    "        conn.close()\n",
    "        \n",
    "        \n",
    "        \n",
    "    def answer_from_table(self, query):\n",
    "        \n",
    "        try:\n",
    "            conn = pyodbc.connect(connection_string)\n",
    "        except pyodbc.Error as e:\n",
    "            print(f\"Error connecting to Azure SQL Database: {str(e)}\")\n",
    "        answer = []\n",
    "        try:\n",
    "            cursor = conn.cursor()\n",
    "            cursor.execute(query)\n",
    "\n",
    "            # Fetch and print the results\n",
    "            for row in cursor.fetchall():\n",
    "                answer.append(row)\n",
    "                print(row)\n",
    "        except pyodbc.Error as e:\n",
    "            print(f\"Error executing SQL query: {str(e)}\")\n",
    "        cursor.close()\n",
    "        conn.close()\n",
    "            \n",
    "        return answer\n",
    "    \n",
    "    def describe_table(self, table_name, columns):\n",
    "        # Convert the columns dictionary into a formatted string\n",
    "        column_descriptions = ', '.join([f\"'{col}'({data_type})\" for col, data_type in columns.items()])\n",
    "\n",
    "        # Generate the final statement\n",
    "        statement = f\"The table '{table_name}' has columns {column_descriptions}.\"\n",
    "\n",
    "        return statement\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636b9f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_table_schema(table_schema, description):\n",
    "    # Concatenate the description to the existing table_schema with a line break\n",
    "    table_schema += f\"\\n{description}\"\n",
    "    return table_schema\n",
    "\n",
    "# Example usage:\n",
    "# table_schema = \"The schema of the tables are as follows:-\"\n",
    "table_schema = \"\"\"The schema of the tables are as follows:-\n",
    "The table 'Sample_excel' has columns 'Number'(int), 'Name'(string), 'Gender'(string), 'Age'(int).\n",
    "The table 'Sample_excel' has columns 'Number'(int), 'Name'(string), 'Gender'(string), 'Age'(int).\"\"\"\n",
    "description = \"The table 'Sample_excel' has columns 'Number'(int), 'Name'(string), 'Gender'(string), 'Age'(int).\"\n",
    "\n",
    "# Call the function to update table_schema\n",
    "table_schema = update_table_schema(table_schema, description)\n",
    "\n",
    "\n",
    "# Print or use the updated table_schema\n",
    "print(table_schema)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79517467",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"Sample_excel.xlsx\"\n",
    "get_data(self, filename)\n",
    "excel_data = pd.read_excel(\"Sample_excel.xlsx\")\n",
    "# Convert column names to lowercase\n",
    "excel_data.columns = excel_data.columns.str.lower()\n",
    "table_insertion(excel_data)\n",
    "sql_table_name, extension = filename.split(\".\")\n",
    "\n",
    "columns_type = {}\n",
    "for column_name, dtype in excel_data.dtypes.items():\n",
    "    if dtype == 'int64':\n",
    "        columns_type[column_name] = 'int'\n",
    "    elif dtype == 'float64':\n",
    "        columns_type[column_name] = 'float'\n",
    "    elif dtype == 'bool':\n",
    "        columns_type[column_name] = 'boolean'\n",
    "    elif dtype == 'datetime64[ns]':\n",
    "        columns_type[column_name] = 'datetime'\n",
    "    else:\n",
    "        columns_type[column_name] = 'VARCHAR(MAX)'\n",
    "\n",
    "        \n",
    "description = describe_table(sql_table_name, columns_type)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77ec5d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a689956f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75362e99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e3386e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc93141",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ecbc43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f07308",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
